---
layout: post
title: Sentence Transformer Fine-Tuning - SetFit
date: 2023-10-22 00:00:00
tags: sentence-transformers BERT triplet-loss embeddings fine-tuning setfit
categories: [blog]
comments: true
disqus_identifier: 20231023
preview_pic: /assets/images/2023-10-23-SetFit.png
---


SetFit is a technique to fine-tune pre-trained pre-trained `sentence-transformers` on a small number of text pairs, in a contrastive Siamese manner. The resulting model is then used to generate rich text embeddings, which are used to train a classification head. 



## __Introduction__


https://nips.cc/virtual/2022/59465



### __References__

Efficient Few-Shot Learning with Sentence Transformers: https://www.youtube.com/watch?v=8h27lV8v8BU&t=1405s


https://towardsdatascience.com/sentence-transformer-fine-tuning-setfit-outperforms-gpt-3-on-few-shot-text-classification-while-d9a3788f0b4e

https://lilianweng.github.io/posts/2021-05-31-contrastive/

Contrastive Learning in PyTorch - Part 1: Introduction https://www.youtube.com/watch?v=u-X_nZRsn5M