---
layout: post
title: Sentence Transformer Fine-Tuning - SetFit
date: 2023-10-23 00:00:00
tags: sentence-transformers triplet-loss contrastive-learning fine-tuning
categories: [blog]
comments: true
disqus_identifier: 20231023
preview_pic: /assets/images/2023-10-23-SetFit.png
---


Sentence Transformers Fine-Tunning (SetFit) is a technique to mitigate the problem of a few annotated samples by fine-tuning a pre-trained `sentence-transformers` model on a small number of text pairs in a contrastive learning manner. The resulting model is then used to generate rich text embeddings, which are then used to train a classification head, resulting in a final classifier fine-tuned to the specific dataset.


<figure>
  <img style="width: 95%; height: 50%" src="/assets/images/2023-10-23-SetFit-2-phases.png">
  <figcaption>Figure 1 - SetFit two phases.</figcaption>
</figure>



### __Contrastive Learning__

The first step relies on a __sentence-transformer__ model and adapts a contrastive training approach that is often used for image similarity detection (Koch et al., 2015).

The basic contrastive learning framework consists of selecting a data sample, called __anchor__ a data point belonging to the same distribution as the anchor, called the __positive__ sample, and another data point belonging to a different distribution called the __negative__ sample, as shown in Figure 1. 

The model tries to __minimize the distance between the anchor and positive sample__ and, at the same time, __maximize the distance between the anchor and the negative samples__. The distance function can be anything in the embedding space.

<figure>
  <img style="width: 75%; height: 50%" src="/assets/images/2023-10-23-SetFit-constrative-learning.png">
  <figcaption>Figure 1 - Contrastive Learning from Vision AI <a href="https://www.v7labs.com/blog/contrastive-learning-guide#h1">(source)</a>.</figcaption>
</figure>


### __Selecting Positive and Negative Triples__

Given a dataset of $$K$$ labeled examples 

$$D = {(x_i, y_i)}$$

where $$x_i$$ and $$y_i$$ are sentences and their class labels, respectively.

For each class label $$c \in C$$ in the dataset we need to generate a set of __positive triples__:

$$T_{p}^{c} = {(x_{i},x_{j}, 1)}$$

where $$x_{i}$$ and $$x_{j}$$ are pairs of randomly chosen sentences from the same class $$c$$, i.e $$(y_{i} = y_{j} = c)$$

and, also a set of __negative triples__:

$$T_{n}^{c} = {(x_{i} , x_{j} , 0)}$$

where $$x_{i}$$ and $$x_{j}$$ are randomly chosen sentences from different classes such that $$(y_{i} = c, y_{j} \neq c)$$. 


### __Building the Contrastive Fine-tuning Dataset__

The contrastive fine-tuning data set $$T$$ is produced by concatenating the positive and negative triplets across all class labels:

$$T = { (T_{p}^{0},T{n}^{0}), (T_{p}^{1},T{n}^{1}), \ldots, (T_{p}^{|C|}, T_{n}^{|C|}) }$$ 

$$ \vert C \vert $$ is the number of class labels

$$ \vert T \vert = 2R \vert C \vert $$ 

is the number of pairs in $$T$$ and $$R$$ is a hyperparameter. 



### __Fine-Tuning__

The contrastive fine-tuning dataset is then used to fine-tune the pre-trained `sentence-transformer` model using a 
contrastive loss function. The contrastive loss function is designed to minimize the distance between the anchor and 
positive samples and maximize the distance between the anchor and negative samples.

<figure>
  <img style="width: 95%; height: 50%" src="/assets/images/2023-10-23-SetFit-phase-2.png">
  <figcaption>Figure 2 - The new embedded latent space after siamese contrastive learning.</figcaption>
</figure>


### __Training Classification Head__

This step is a standard supervised learning task, where the fine-tuned sentence-transformer model is used to generate  embeddings for the training data, and a classification head is trained on top of the embeddings to predict the class labels.


### __References__

- __[Original paper: Efficient Few-Shot Learning Without Prompts (PDF)](https://neurips2022-enlsp.github.io/papers/paper_17.pdf)__

- __[Weng, Lilian. (May 2021). Contrastive representation learning. Lil’Log](https://lilianweng.github.io/posts/2021-05-31-contrastive/)__

- __[Efficient Few-Shot Learning with Sentence Transformers](https://www.youtube.com/watch?v=8h27lV8v8BU&t=1405s)__

- __[Sentence Transformer Fine-Tuning post on Towards Data Science by Moshe Wasserblat](https://towardsdatascience.com/sentence-transformer-fine-tuning-setfit-outperforms-gpt-3-on-few-shot-text-classification-while-d9a3788f0b4e)__

- __[Video Presentation at the NIPS Workshop ENLSP-II](https://nips.cc/virtual/2022/59465)__

- __[The Beginner’s Guide to Contrastive Learning from v7labs](https://www.v7labs.com/blog/contrastive-learning-guide)__

- __[Siamese Neural Networks for One-shot Image Recognition](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)__

- __[Learning a Similarity Metric Discriminatively, with Application to Face Verification](http://yann.lecun.com/exdb/publis/pdf/chopra-05.pdf)__
