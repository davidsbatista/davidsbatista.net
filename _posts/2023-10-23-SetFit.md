---
layout: post
title: Sentence Transformer Fine-Tuning - SetFit
date: 2023-10-22 00:00:00
tags: sentence-transformers triplet-loss contrastive-learning fine-tuning
categories: [blog]
comments: true
disqus_identifier: 20231023
preview_pic: /assets/images/2023-10-23-SetFit.png
---


Sentence Transformers Fine-Tunning (SetFit) is a technique to mitigate the problem of a few annotated samples by fine-tuning a pre-trained `sentence-transformers` model on a small number of text pairs in a contrastive learning manner. The resulting model is then used to generate rich text embeddings, which are then used to train a classification head, resulting in a final classifier fine-tuned to the specific dataset.


<figure>
  <img style="width: 95%; height: 50%" src="/assets/images/2023-10-23-SetFit-2-phases.png">
  <figcaption>Figure 1 - SetFit two phases.</figcaption>
</figure>



### __ST Fine-Tuning with Contrastive Learning__

The first step relies on a __sentence-transformer__ model and adapts a contrastive training approach that is often used for image similarity detection (Koch et al., 2015).

The basic contrastive learning framework consists of selecting a data sample, called __anchor__ a data point belonging to the same distribution as the anchor, called the __positive__ sample, and another data point belonging to a different distribution called the __negative__ sample.

<figure>
  <img style="width: 60%; height: 50%" src="/assets/images/2023-10-23-SetFit-constrative-learning.png">
  <figcaption>Figure 1 - Contrastive Learning from Vision AI <a href="https://www.v7labs.com/blog/contrastive-learning-guide#h1">(source)</a>.</figcaption>
</figure>

The model tries to __minimize the distance between the anchor and positive samples__ and, at the same time __maximize the distance between the anchor and the negative samples__.

The image below shows the basic framework of the instance discrimination-based contrastive learning technique. The distance function can be anything, from Euclidean distance to cosine distances in the embedding space.


Given a set $$S$$ of sentences and set $$L$$ of labels for each sentence:

$$S = (s_{1} , s_{2}, \ldots, s_{n})$$ 

$$L = (l_{1} , l_{2}, \ldots, l_{n})$$ 

For each $$s_{i}$$ sample a $$s_{j}$$ such that $$l_{i} = l_{j}$$ and  $$s_{k}$$ such that $$s_{i} != s_{k}$$, this will result in two sets of triples:

Positive triples $$(s_{i}, s_{j}, l{i})$$ 

Negative triples $$(s_{i}, s_{k}, l{i})$$ 





[Siamese Neural Networks for One-shot Image Recognition](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)

[Learning a Similarity Metric Discriminatively, with Application to Face Verification](http://yann.lecun.com/exdb/publis/pdf/chopra-05.pdf)



<!--
For each class label $$c \in C$$, we generate a set of positive and negative triples:

$$T_{p}^{c} = {(x_{i},x_{j}, 1)}$$

$$T_{n}^{c} = {(x_{i} , x_{j} , 0)}$$

where $$x_{i}$$ and $$x_{j}$$ are pairs of randomly chosen sentences from the same class $$c$$, i.e $$(y_{i} = y_{j} = c)$$

$$x_{i}$$: sentences from class $$c$$

$$x_{j}$$: are randomly chosen sentences from different classes such that $$(y_{i} = c, y_{j} \neq c)$$. 

The contrastive fine tuning data set $$T$$ is produced by concatenating the positive and negative triplets across all class labels:

$$T = { (T_{p}^{0},T{n}^{0}), (T_{p}^{1},T{n}^{1}), \ldots, (T_{p}^{|C|}, T_{n}^{|C|}) }$$ 

$$ \vert C \vert $$ is the number of class labels

$$ \vert T \vert = 2R \vert C \vert $$ 

is the number of pairs in $$T$$ and $$R$$ is a hyperparameter. 


<figure>
  <img style="width: 95%; height: 50%" src="/assets/images/2023-10-23-SetFit-phase-1.png">
  <figcaption>Figure 1 - SetFit two phases.</figcaption>
</figure>

-->

<figure>
  <img style="width: 95%; height: 50%" src="/assets/images/2023-10-23-SetFit-phase-2.png">
  <figcaption>Figure 2 - The new embedded latent space after siamese contrastive learning.</figcaption>
</figure>





## __Training Classification Head__



<!--
SETFIT is based on Sentence Transformers (Reimers and Gurevych, 2019) which are modifications of pre-trained transformer models that use Siamese and Triplet network structures to derive se- mantically meaningful sentence embeddings. The goal of these models is to minimize the distance be- tween pairs of semantically similar sentences and maximize the distance between sentence pairs that are semantically distant.


SETFIT uses a two-step training approach in which we first fine-tune an ST and then train a classifier head. In the first step, an ST is fine-tuned on the input data in a contrastive, Siamese manner on sentence pairs. In the second step, a text classifica- tion head is trained using the encoded training data generated by the fine-tuned ST from the first step.
-->



<!--
	Contrastive Learning in PyTorch - Part 1: Introduction https://www.youtube.com/watch?v=u-X_nZRsn5M
-->






### __Overview__

In retrospective, and starting with a pre-trained vanilla Transformer model (e.g.: BERT, RoBERTa), by applying the __[SBERT](blog/2023/10/22/SentenceTransformers)__ approach of fine-tuning for semantically (dis)similarity you get a fine-tuned `sentence-transformer`, which given two similar sentences it will generate embeddings that are also close in the embedding space.


<figure>
  <img style="width: 50%; height: 50%" src="/assets/images/2023-10-23-SetFit.png">
  <figcaption>Figure 1 - SetFit general approach.</figcaption>
</figure>









### __References__

- __[Original paper: Efficient Few-Shot Learning Without Prompts (PDF)](https://neurips2022-enlsp.github.io/papers/paper_17.pdf)__

- __[Weng, Lilian. (May 2021). Contrastive representation learning. Lil’Log](https://lilianweng.github.io/posts/2021-05-31-contrastive/)__

- __[Efficient Few-Shot Learning with Sentence Transformers](https://www.youtube.com/watch?v=8h27lV8v8BU&t=1405s)__

- __[Sentence Transformer Fine-Tuning post on Towards Data Science by Moshe Wasserblat](https://towardsdatascience.com/sentence-transformer-fine-tuning-setfit-outperforms-gpt-3-on-few-shot-text-classification-while-d9a3788f0b4e)__

- __[Video Presentation at the NIPS Workshop ENLSP-II](https://nips.cc/virtual/2022/59465)__

- __[The Beginner’s Guide to Contrastive Learning from v7labs](https://www.v7labs.com/blog/contrastive-learning-guide)__
